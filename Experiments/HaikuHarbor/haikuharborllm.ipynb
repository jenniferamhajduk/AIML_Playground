{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Credit: https://www.youtube.com/watch?v=kCc8FmEb1nY&t=6s\n",
    "### This is an LLM that will be trained to generate poetry, hopefully haikus. This is a fun experiment. Haikus were created with OpenAI GPT-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = './haikus.txt'\n",
    "with open(file_path, 'r') as file:\n",
    "    contents = file.read()\n",
    "\n",
    "contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_chars = sorted(list(set(contents)))\n",
    "unique_chars_len = len(unique_chars)\n",
    "print(''.join(unique_chars))\n",
    "print(unique_chars_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets try One Hot Encoding and pring out vocab dictionary\n",
    "\n",
    "def one_hot_encode(data_input, char_set):\n",
    "    # Create a dictionary mapping each character to its index\n",
    "    char_to_index = {ch: i for i, ch in enumerate(char_set)}\n",
    "    vector_set = []\n",
    "\n",
    "    for i in list(data_input):\n",
    "    # Initialize a vector of zeros with the length of the character set\n",
    "        one_hot_vector = [0] * len(char_set)\n",
    "\n",
    "        # Set the position corresponding to the character to 1\n",
    "        if i in char_to_index:\n",
    "            one_hot_vector[char_to_index[i]] = 1\n",
    "            vector_set.append(one_hot_vector)\n",
    "        else:\n",
    "            raise ValueError(f\"Character '{i}' not in character set\")\n",
    "\n",
    "    return vector_set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decoder\n",
    "def one_hot_decode(encoded_data, char_set):\n",
    "    # Create a dictionary mapping each index to its character\n",
    "    index_to_char = {i: ch for i, ch in enumerate(char_set)}\n",
    "\n",
    "    decoded_string = \"\"\n",
    "\n",
    "    for vector in encoded_data:\n",
    "        # Find the index of the 1 in the vector\n",
    "        index = vector.index(1)\n",
    "\n",
    "        # Append the corresponding character to the decoded string\n",
    "        decoded_string += index_to_char[index]\n",
    "\n",
    "    return decoded_string\n",
    "\n",
    "# Example usage\n",
    "char_set = ',.ABCDGHILMNOPRSTUWabcdefghiklmnopqrstuvwyz'\n",
    "data_input = \"Hello\"\n",
    "encoded_data = one_hot_encode(data_input, char_set)\n",
    "print(encoded_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test the encoding\n",
    "encoding = one_hot_encode(unique_chars, unique_chars)\n",
    "print(encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test the decoding\n",
    "decoding = one_hot_decode(encoding, unique_chars)\n",
    "print(decoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's Encode our Data\n",
    "prepped_data = contents#.replace(\" \", \"\")\n",
    "prepped_data\n",
    "encoded_data = one_hot_encode(prepped_data, unique_chars)\n",
    "print(encoded_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transform encoded data into Tensor\n",
    "tensor_data = torch.tensor(encoded_data, dtype=torch.float32)\n",
    "print(tensor_data.shape, tensor_data.dtype)\n",
    "print(tensor_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train and Validation Sets\n",
    "n = int(0.8*len(tensor_data))\n",
    "train = tensor_data[:n]\n",
    "val = tensor_data[n:]\n",
    "print(train)\n",
    "print(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "block_size = 8\n",
    "train[:block_size + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = train[:block_size]\n",
    "y = train[1:block_size+1]\n",
    "for t in range(block_size):\n",
    "    context = x[:t+1]\n",
    "    target = y[t]\n",
    "    print(f\"When the input is {context}, the target is {target}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Introducing the batch dimension\n",
    "torch.manual_seed(1337)\n",
    "batch_size = 4\n",
    "block_size = 8\n",
    "\n",
    "\n",
    "def get_batch(split):\n",
    "    data = train if split == 'train' else val\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix]) \n",
    "    return x, y  \n",
    "\n",
    "xb, yb = get_batch('train')\n",
    "print(\"inputs:\")\n",
    "print(xb.shape)\n",
    "print(xb)\n",
    "print('targets')\n",
    "print(yb.shape)\n",
    "print(yb)\n",
    "\n",
    "print(\"-----\")\n",
    "\n",
    "for b in range(batch_size):\n",
    "    for t in range(block_size):\n",
    "        context = xb[b, :t+1]\n",
    "        target = yb[b,t]\n",
    "        print(f\"when the input is {context.tolist()}, the target is: {target}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = train[:block_size]\n",
    "y = train[1:block_size+1]\n",
    "for t in range(block_size):\n",
    "    context = x[:t+1]\n",
    "    target = y[t]\n",
    "    print(f\"When context is {context}, the target is {target}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RNN can handle One-Hot vectors well\n",
    "class SimpleRNNModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(SimpleRNNModel, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        # RNN layer\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, batch_first=True)\n",
    "\n",
    "        # Output layer\n",
    "        self.linear = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(1, x.size(0), self.hidden_size)\n",
    "        out, hidden = self.rnn(x, h0)\n",
    "        out = out.contiguous().view(-1, self.hidden_size)\n",
    "        out = self.linear(out)\n",
    "        return out\n",
    "\n",
    "   \n",
    "\n",
    "        \n",
    "model = SimpleRNNModel(unique_chars_len, 128, unique_chars_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "# Optimizer (example: using Adam)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data, targets):\n",
    "        self.data = data\n",
    "        self.targets = targets\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.targets[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming train_data and train_targets are your data tensors\n",
    "train_dataset = CustomDataset(xb, yb)\n",
    "\n",
    "# Create the DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 500\n",
    "previous_loss = float('inf') #somthing ridiculous to start out with\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for batch in train_loader:  # Assuming you have a DataLoader\n",
    "        # Split batch data\n",
    "        x_batch, y_batch = batch  # x_batch is input, y_batch is target labels\n",
    "        y_batch = y_batch.view(-1, unique_chars_len) #Need to reshape in order to meet the expected shape of the models output\n",
    "        \n",
    "        # Forward pass: Compute predicted y by passing x to the model\n",
    "        y_pred = model(x_batch)\n",
    "        \n",
    "        # Compute and print loss\n",
    "        current_loss = loss_function(y_pred, y_batch)\n",
    "\n",
    "        #Save the model if the loss is not improving\n",
    "        if current_loss < previous_loss:\n",
    "            previous_loss = current_loss\n",
    "            torch.save(model.state_dict(), 'best_model.pth')\n",
    "\n",
    "        \n",
    "        print(f\"Epoch {epoch}, Loss: {current_loss.item()}\")\n",
    "\n",
    "        # Zero gradients, perform a backward pass, and update the weights.\n",
    "        optimizer.zero_grad()\n",
    "        current_loss.backward()\n",
    "        optimizer.step()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Put it in a function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_function(epochs, train_data_loader, model, b, l):\n",
    "  previous_loss = float('inf')\n",
    "  loss_function = nn.CrossEntropyLoss()\n",
    "  optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "  for epoch in range(epochs):\n",
    "      for batch in train_data_loader:  # Assuming you have a DataLoader\n",
    "        # Split batch data\n",
    "        x_batch, y_batch = batch  # x_batch is input, y_batch is target labels\n",
    "        y_batch = y_batch.view(-1, unique_chars_len) #Need to reshape in order to meet the expected shape of the models output\n",
    "\n",
    "        # Forward pass: Compute predicted y by passing x to the model\n",
    "        y_pred = model(x_batch)\n",
    "\n",
    "        # Compute and print loss\n",
    "        current_loss = loss_function(y_pred, y_batch)\n",
    "\n",
    "        if current_loss < previous_loss:\n",
    "           previous_loss = current_loss\n",
    "           torch.save(model, \"best_model_batch_{}_layers_{}_epochs_{}.pth\".format(b, l, epochs))\n",
    "\n",
    "        print(f\"Epoch {epoch}, Loss: {current_loss.item()}\")\n",
    "\n",
    "        # Zero gradients, perform a backward pass, and update the weights.\n",
    "        optimizer.zero_grad()\n",
    "        current_loss.backward()\n",
    "        optimizer.step()\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train using different hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_sizes = [8, 16, 32, 64]\n",
    "num_epochs = [500, 1000, 10000]\n",
    "layers = [128, 256, 512]\n",
    "\n",
    "\n",
    "for batch in batch_sizes:\n",
    "    train_loader = DataLoader(train_dataset, batch_size, shuffle=True)\n",
    "    for layer in layers:\n",
    "        model = SimpleRNNModel(unique_chars_len, layer, unique_chars_len)\n",
    "        for epochs in num_epochs:\n",
    "            print(\"Size (hidden state): {} Epoch: {} Batch Size: {}\".format(layer, epochs, batch))\n",
    "            train_function(epochs, train_loader, model, batch, layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a function that can generate text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, start_input, char_to_index, index_to_char, max_length=100):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    \n",
    "    # Ensure start_input is a tensor with shape [1, input_size]\n",
    "    input_seq = torch.tensor(start_input, dtype=torch.float).unsqueeze(0).unsqueeze(0)  # [1, 1, input_size]\n",
    "    generated_text = \"\"\n",
    "    hidden = torch.zeros(1, 1, model.hidden_size)  # Shape: [1, 1, hidden_size]\n",
    "\n",
    "   \n",
    "\n",
    "    for _ in range(max_length):\n",
    "        # Forward pass\n",
    "        out, hidden = model.rnn(input_seq, hidden)\n",
    "        out = model.linear(out.squeeze(1))  # Remove the sequence length dimension\n",
    "\n",
    "        # Get the character with the highest probability\n",
    "        _, predicted_index = torch.max(out, dim=1)\n",
    "        last_char_index = predicted_index.item()\n",
    "        generated_text += index_to_char[last_char_index]\n",
    "\n",
    "        # Prepare the next input\n",
    "\n",
    "        input_seq = torch.zeros((1, 1, len(char_to_index)))  # Shape: [1, 1, input_size]\n",
    "        input_seq[0, 0, last_char_index] = 1.0  # Set the correct character index to 1\n",
    "\n",
    "    return generated_text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterate through model files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = './'\n",
    "pattern = \"best_model_batch*.pth\"\n",
    "search_pattern = f\"{model_dir}/{pattern}\"\n",
    "model_files = glob.glob(search_pattern)\n",
    "print(model_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets see which model performs the best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "starting_vector = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] #start with a capital letter\n",
    "for file in model_files:\n",
    "    model = torch.load(file)\n",
    "    print(\"Loading model: {}\".format(file))\n",
    "    model_text = generate_text(model, starting_vector, encoding, decoding, max_length=100)\n",
    "    print(model_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
