{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Citations:\n",
    "## The data used for this example: https://www.kaggle.com/datasets/fournierp/captcha-version-2-images\n",
    "## Ensure that you place the .png files from this dataset into the samples folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import math\n",
    "import os\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 64, 3)\n"
     ]
    }
   ],
   "source": [
    "# We have images from Kaggles CAPTCHA images. Let's gather and resize them. Resizing images can help with computational complexity\n",
    "images = os.listdir('./samples/')\n",
    "image_data = []\n",
    "for image in images:\n",
    "    img = load_img('./samples/' + image, target_size=(64, 64))  # Resize images to desired dimensions\n",
    "    img_array = img_to_array(img)\n",
    "    image_data.append(img_array)\n",
    "image_data = np.array(image_data)\n",
    "#print(image_data)\n",
    "image_data = image_data.astype('float32') / 255.0  # Normalize pixel values to [0, 1]\n",
    "print(np.shape(image_data[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to split our image data into training and test data, minimally. You can also split into training, test, and validation data if you choose\n",
    "split_index = len(image_data) * .8\n",
    "#print(split_index)\n",
    "train = image_data[:int(split_index)]\n",
    "test = image_data[int(split_index) + 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have to build our autoencoder. Our images have the shape (64, 64, 3). We want to save a potion of our images for validation. We will save 20% for this purpose\n",
    "# We need to perform the following steps:\n",
    "# 1. Set out input layer based on the shape of our data\n",
    "# 2. Flatten our input layer to be fed into the Dense layers.\n",
    "# 3. Encode the data to a lower dimension\n",
    "# 4. Decode the layer back to the original dimension\n",
    "# 5. Input our model parameters. This is our autoencoder\n",
    "# 6. Compile the autoencoder\n",
    "# 7. Train the autoencoder\n",
    "# 8. Get predictions and the best model\n",
    "\n",
    "\n",
    "input_layer = Input(shape=(64, 64, 3))\n",
    "flattened_input = tf.keras.layers.Flatten()(input_layer)\n",
    "\n",
    "encoded = Dense(32, activation='relu')(flattened_input)\n",
    "decoded = Dense(64 * 64 * 3, activation='sigmoid')(encoded)\n",
    "\n",
    "reshaped_output = tf.keras.layers.Reshape((64, 64, 3))(decoded)\n",
    "autoencoder = Model(input_layer, reshaped_output)\n",
    "\n",
    "model_checkpoint = ModelCheckpoint(\n",
    "    filepath='./best_model.h5',\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True,\n",
    "    save_weights_only=False,\n",
    "    mode='auto',\n",
    "    verbose=0\n",
    ")\n",
    "autoencoder.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "autoencoder.fit(\n",
    "    train, \n",
    "    train, \n",
    "    epochs=100, \n",
    "    batch_size=8,\n",
    "    callbacks=[model_checkpoint],\n",
    "    shuffle=True,\n",
    "    validation_data=(test, test)\n",
    ")\n",
    "\n",
    "predictions = autoencoder.predict(\n",
    "    test\n",
    ")\n",
    "\n",
    "display(test, predictions)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Play with the model hyperparameters to see if you can improve accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
