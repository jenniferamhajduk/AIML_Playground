{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Citations:\n",
    "## The data used for this example: https://www.kaggle.com/datasets/fournierp/captcha-version-2-images\n",
    "## Ensure that you place the .png files from this dataset into the samples folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import math\n",
    "import os\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have images from Kaggles CAPTCHA images. Let's gather and resize them. Resizing images can help with computational complexity\n",
    "images = os.listdir('./samples/')\n",
    "image_data = []\n",
    "for image in images:\n",
    "    img = load_img('./samples/' + image, target_size=(64, 64))  # Resize images to desired dimensions\n",
    "    img_array = img_to_array(img)\n",
    "    image_data.append(img_array)\n",
    "image_data = np.array(image_data)\n",
    "#print(image_data)\n",
    "image_data = image_data.astype('float32') / 255.0  # Normalize pixel values to [0, 1]\n",
    "#print(np.shape(image_data[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to split our image data into training and test data, minimally. You can also split into training, test, and validation data if you choose\n",
    "split_index = len(image_data) * .8\n",
    "#print(split_index)\n",
    "train = image_data[:int(split_index)]\n",
    "test = image_data[int(split_index) + 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unexpected result of `train_function` (Empty logs). This could be due to issues in input pipeline that resulted in an empty dataset. Otherwise, please use `Model.compile(..., run_eagerly=True)`, or `tf.config.run_functions_eagerly(True)` for more information of where went wrong, or file a issue/bug to `tf.keras`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/jenniferhajduk/Repositories/AIML_Playground/Machine_Learning_Algorithms/GenAI_Project_Based_Learning/Autoencoder/autoencoder.ipynb Cell 5\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jenniferhajduk/Repositories/AIML_Playground/Machine_Learning_Algorithms/GenAI_Project_Based_Learning/Autoencoder/autoencoder.ipynb#W4sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m model_checkpoint \u001b[39m=\u001b[39m ModelCheckpoint(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jenniferhajduk/Repositories/AIML_Playground/Machine_Learning_Algorithms/GenAI_Project_Based_Learning/Autoencoder/autoencoder.ipynb#W4sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m     filepath\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m./best_model.h5\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jenniferhajduk/Repositories/AIML_Playground/Machine_Learning_Algorithms/GenAI_Project_Based_Learning/Autoencoder/autoencoder.ipynb#W4sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m     monitor\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mval_loss\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jenniferhajduk/Repositories/AIML_Playground/Machine_Learning_Algorithms/GenAI_Project_Based_Learning/Autoencoder/autoencoder.ipynb#W4sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m     verbose\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jenniferhajduk/Repositories/AIML_Playground/Machine_Learning_Algorithms/GenAI_Project_Based_Learning/Autoencoder/autoencoder.ipynb#W4sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jenniferhajduk/Repositories/AIML_Playground/Machine_Learning_Algorithms/GenAI_Project_Based_Learning/Autoencoder/autoencoder.ipynb#W4sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m autoencoder\u001b[39m.\u001b[39mcompile(optimizer\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39madam\u001b[39m\u001b[39m'\u001b[39m, loss\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmse\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/jenniferhajduk/Repositories/AIML_Playground/Machine_Learning_Algorithms/GenAI_Project_Based_Learning/Autoencoder/autoencoder.ipynb#W4sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m autoencoder\u001b[39m.\u001b[39;49mfit(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jenniferhajduk/Repositories/AIML_Playground/Machine_Learning_Algorithms/GenAI_Project_Based_Learning/Autoencoder/autoencoder.ipynb#W4sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m     train, \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jenniferhajduk/Repositories/AIML_Playground/Machine_Learning_Algorithms/GenAI_Project_Based_Learning/Autoencoder/autoencoder.ipynb#W4sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m     train, \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jenniferhajduk/Repositories/AIML_Playground/Machine_Learning_Algorithms/GenAI_Project_Based_Learning/Autoencoder/autoencoder.ipynb#W4sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m     epochs\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m, \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jenniferhajduk/Repositories/AIML_Playground/Machine_Learning_Algorithms/GenAI_Project_Based_Learning/Autoencoder/autoencoder.ipynb#W4sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m     batch_size\u001b[39m=\u001b[39;49m\u001b[39m8\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jenniferhajduk/Repositories/AIML_Playground/Machine_Learning_Algorithms/GenAI_Project_Based_Learning/Autoencoder/autoencoder.ipynb#W4sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m     callbacks\u001b[39m=\u001b[39;49m[model_checkpoint],\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jenniferhajduk/Repositories/AIML_Playground/Machine_Learning_Algorithms/GenAI_Project_Based_Learning/Autoencoder/autoencoder.ipynb#W4sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m     shuffle\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jenniferhajduk/Repositories/AIML_Playground/Machine_Learning_Algorithms/GenAI_Project_Based_Learning/Autoencoder/autoencoder.ipynb#W4sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m     validation_data\u001b[39m=\u001b[39;49m(test, test)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jenniferhajduk/Repositories/AIML_Playground/Machine_Learning_Algorithms/GenAI_Project_Based_Learning/Autoencoder/autoencoder.ipynb#W4sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jenniferhajduk/Repositories/AIML_Playground/Machine_Learning_Algorithms/GenAI_Project_Based_Learning/Autoencoder/autoencoder.ipynb#W4sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m predictions \u001b[39m=\u001b[39m autoencoder\u001b[39m.\u001b[39mpredict(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jenniferhajduk/Repositories/AIML_Playground/Machine_Learning_Algorithms/GenAI_Project_Based_Learning/Autoencoder/autoencoder.ipynb#W4sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m     test\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jenniferhajduk/Repositories/AIML_Playground/Machine_Learning_Algorithms/GenAI_Project_Based_Learning/Autoencoder/autoencoder.ipynb#W4sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jenniferhajduk/Repositories/AIML_Playground/Machine_Learning_Algorithms/GenAI_Project_Based_Learning/Autoencoder/autoencoder.ipynb#W4sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m display(test, predictions)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/keras/src/engine/training.py:1754\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1752\u001b[0m logs \u001b[39m=\u001b[39m tf_utils\u001b[39m.\u001b[39msync_to_numpy_or_python_type(logs)\n\u001b[1;32m   1753\u001b[0m \u001b[39mif\u001b[39;00m logs \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1754\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1755\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mUnexpected result of `train_function` \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1756\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m(Empty logs). This could be due to issues in input \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1757\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mpipeline that resulted in an empty dataset. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1758\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mOtherwise, please use \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1759\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m`Model.compile(..., run_eagerly=True)`, or \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1760\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m`tf.config.run_functions_eagerly(True)` for more \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1761\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39minformation of where went wrong, or file a \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1762\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39missue/bug to `tf.keras`.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1763\u001b[0m     )\n\u001b[1;32m   1764\u001b[0m \u001b[39m# Override with model metrics instead of last step logs\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_and_get_metrics_result(logs)\n",
      "\u001b[0;31mValueError\u001b[0m: Unexpected result of `train_function` (Empty logs). This could be due to issues in input pipeline that resulted in an empty dataset. Otherwise, please use `Model.compile(..., run_eagerly=True)`, or `tf.config.run_functions_eagerly(True)` for more information of where went wrong, or file a issue/bug to `tf.keras`."
     ]
    }
   ],
   "source": [
    "# We have to build our autoencoder. Our images have the shape (64, 64, 3). We want to save a potion of our images for validation. We will save 20% for this purpose\n",
    "# We need to perform the following steps:\n",
    "# 1. Set out input layer based on the shape of our data\n",
    "# 2. Flatten our input layer to be fed into the Dense layers.\n",
    "# 3. Encode the data to a lower dimension\n",
    "# 4. Decode the layer back to the original dimension\n",
    "# 5. Input our model parameters. This is our autoencoder\n",
    "# 6. Compile the autoencoder\n",
    "# 7. Train the autoencoder\n",
    "# 8. Get predictions and the best model\n",
    "\n",
    "\n",
    "input_layer = Input(shape=(64, 64, 3))\n",
    "flattened_input = tf.keras.layers.Flatten()(input_layer)\n",
    "\n",
    "encoded = Dense(32, activation='relu')(flattened_input)\n",
    "decoded = Dense(64 * 64 * 3, activation='sigmoid')(encoded)\n",
    "\n",
    "reshaped_output = tf.keras.layers.Reshape((64, 64, 3))(decoded)\n",
    "autoencoder = Model(input_layer, reshaped_output)\n",
    "\n",
    "model_checkpoint = ModelCheckpoint(\n",
    "    filepath='./best_model.h5',\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True,\n",
    "    save_weights_only=False,\n",
    "    mode='auto',\n",
    "    verbose=0\n",
    ")\n",
    "autoencoder.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "autoencoder.fit(\n",
    "    train, \n",
    "    train, \n",
    "    epochs=100, \n",
    "    batch_size=8,\n",
    "    callbacks=[model_checkpoint],\n",
    "    shuffle=True,\n",
    "    validation_data=(test, test)\n",
    ")\n",
    "\n",
    "predictions = autoencoder.predict(\n",
    "    test\n",
    ")\n",
    "\n",
    "display(test, predictions)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Play with the model hyperparameters to see if you can improve accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
